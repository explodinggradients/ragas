{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "> A python list like object that contains your evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from unittest.mock import MagicMock\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import typing as t\n",
    "\n",
    "from fastcore.utils import patch\n",
    "import pandas as pd\n",
    "\n",
    "from ragas_experimental.model.pydantic_model import ExtendedPydanticBaseModel as BaseModel\n",
    "from ragas_experimental.utils import create_nano_id, async_to_sync\n",
    "from ragas_experimental.backends.ragas_api_client import RagasApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "BaseModelType = t.TypeVar(\"BaseModelType\", bound=BaseModel)\n",
    "\n",
    "class Dataset(t.Generic[BaseModelType]):\n",
    "    \"\"\"A list-like interface for managing dataset entries with backend synchronization.\n",
    "    \n",
    "    This class behaves like a Python list while synchronizing operations with the\n",
    "    Ragas backend API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        model: t.Type[BaseModel],\n",
    "        project_id: str,\n",
    "        dataset_id: str,\n",
    "        ragas_api_client: RagasApiClient,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.project_id = project_id\n",
    "        self.dataset_id = dataset_id\n",
    "        self._ragas_api_client = ragas_api_client\n",
    "        self._entries: t.List[BaseModelType] = []\n",
    "\n",
    "        # Initialize column mapping if it doesn't exist yet\n",
    "        if not hasattr(self.model, \"__column_mapping__\"):\n",
    "            self.model.__column_mapping__ = {}\n",
    "            \n",
    "        # Get column mappings from API and update the model's mapping\n",
    "        column_id_map = self._get_column_id_map(dataset_id=dataset_id)\n",
    "        \n",
    "        # Update the model's column mapping with the values from the API\n",
    "        for field_name, column_id in column_id_map.items():\n",
    "            self.model.__column_mapping__[field_name] = column_id\n",
    "\n",
    "    def _get_column_id_map(self: \"Dataset\", dataset_id: str) -> dict:\n",
    "        \"\"\"Get a map of column name to column id\"\"\"\n",
    "        sync_func = async_to_sync(self._ragas_api_client.list_dataset_columns)\n",
    "        columns = sync_func(project_id=self.project_id, dataset_id=dataset_id)\n",
    "        column_id_map = {column[\"name\"]: column[\"id\"] for column in columns[\"items\"]}\n",
    "\n",
    "        # add the column id map to the model, selectively overwriting existing column mapping\n",
    "        for field in self.model.__column_mapping__.keys():\n",
    "            if field in column_id_map:\n",
    "                self.model.__column_mapping__[field] = column_id_map[field]\n",
    "        return column_id_map\n",
    "\n",
    "    def __getitem__(\n",
    "        self, key: t.Union[int, slice]\n",
    "    ) -> t.Union[BaseModelType, \"Dataset[BaseModelType]\"]:\n",
    "        \"\"\"Get an entry by index or slice.\"\"\"\n",
    "        if isinstance(key, slice):\n",
    "            new_dataset = type(self)(\n",
    "                name=self.name,\n",
    "                model=self.model,\n",
    "                project_id=self.project_id,\n",
    "                dataset_id=self.dataset_id,\n",
    "                ragas_api_client=self._ragas_api_client,\n",
    "            )\n",
    "            new_dataset._entries = self._entries[key]\n",
    "            return new_dataset\n",
    "        else:\n",
    "            return self._entries[key]\n",
    "\n",
    "    def __setitem__(self, index: int, entry: BaseModelType) -> None:\n",
    "        \"\"\"Update an entry at the given index and sync to backend.\"\"\"\n",
    "        if not isinstance(entry, self.model):\n",
    "            raise TypeError(f\"Entry must be an instance of {self.model.__name__}\")\n",
    "\n",
    "        # Get existing entry to get its ID\n",
    "        existing = self._entries[index]\n",
    "        \n",
    "        # Update in backend\n",
    "        self.save(entry)\n",
    "        \n",
    "        # Update local cache\n",
    "        self._entries[index] = entry\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Dataset(name={self.name}, model={self.model.__name__}, len={len(self)})\"\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._entries)\n",
    "\n",
    "    def __iter__(self) -> t.Iterator[BaseModelType]:\n",
    "        return iter(self._entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import ragas_experimental.typing as rt\n",
    "from ragas_experimental.backends.factory import RagasApiClientFactory\n",
    "from ragas_experimental.metric.result import MetricResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "class TestModel(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    description: str\n",
    "    tags: t.Literal[\"tag1\", \"tag2\", \"tag3\"]\n",
    "    result: MetricResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestModel.__column_mapping__ = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestModel(id=0, name='test', description='test description', tags='tag1', result=0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = TestModel(\n",
    "    id=0, \n",
    "    name=\"test\", \n",
    "    description=\"test description\", \n",
    "    result=MetricResult(result=0.5, reason=\"test reason\"), \n",
    "    tags=\"tag1\"\n",
    ")\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'id',\n",
       " 'name': 'name',\n",
       " 'description': 'description',\n",
       " 'tags': 'tags',\n",
       " 'result': 'result',\n",
       " 'result_reason': 'result_reason'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.__column_mapping__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ragas_experimental import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGAS_APP_TOKEN = \"api_key\"\n",
    "RAGAS_API_BASE_URL = \"https://api.dev.app.ragas.io\"\n",
    "\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = RAGAS_APP_TOKEN\n",
    "os.environ[\"RAGAS_API_BASE_URL\"] = RAGAS_API_BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_api_client = RagasApiClientFactory.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name=TestModel_with_long_text, model=TestModel, len=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Project(project_id=\"3d9b529b-c23f-4e87-8a26-dd1923749aa7\", ragas_api_client=ragas_api_client)\n",
    "test_dataset = p.create_dataset(name=\"TestModel_with_long_text\", model=TestModel)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'aa1fb420-4820-45a6-9502-6cfb7938b7a3',\n",
       " 'name': 'TestModel_with_long_text',\n",
       " 'description': None,\n",
       " 'created_at': '2025-04-16T18:54:04.355883+00:00',\n",
       " 'updated_at': '2025-04-16T18:54:04.355883+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': '3d9b529b-c23f-4e87-8a26-dd1923749aa7'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://dev.app.ragas.io/dashboard/projects/0a7c4ecb-b313-4bb0-81c0-852c9634ce03/datasets/a4f0d169-ebce-4a2b-b758-0ff49c0c4312\n",
    "TEST_PROJECT_ID = p.project_id\n",
    "TEST_DATASET_ID = test_dataset.dataset_id\n",
    "test_project = await ragas_api_client.get_project(project_id=TEST_PROJECT_ID)\n",
    "test_dataset = await ragas_api_client.get_dataset(project_id=TEST_PROJECT_ID, dataset_id=TEST_DATASET_ID)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    name=\"TestModel\", model=TestModel, project_id=TEST_PROJECT_ID, dataset_id=TEST_DATASET_ID, ragas_api_client=ragas_api_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import ragas_experimental.typing as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def append(self: Dataset, entry: BaseModelType) -> None:\n",
    "    \"\"\"Add a new entry to the dataset and sync to Notion.\"\"\"\n",
    "    # Create row inside the table\n",
    "\n",
    "    # first get the columns for the dataset\n",
    "    column_id_map = self.model.__column_mapping__\n",
    "\n",
    "    # create the rows\n",
    "    row_dict_converted = rt.ModelConverter.instance_to_row(entry)\n",
    "    row_id = create_nano_id()\n",
    "    row_data = {}\n",
    "    for column in row_dict_converted[\"data\"]:\n",
    "        if column[\"column_id\"] in column_id_map:\n",
    "            row_data[column_id_map[column[\"column_id\"]]] = column[\"data\"]\n",
    "\n",
    "    sync_func = async_to_sync(self._ragas_api_client.create_dataset_row)\n",
    "    response = sync_func(\n",
    "        project_id=self.project_id,\n",
    "        dataset_id=self.dataset_id,\n",
    "        id=row_id,\n",
    "        data=row_data,\n",
    "    )\n",
    "    # add the row id to the entry\n",
    "    entry._row_id = response[\"id\"]\n",
    "    # Update entry with Notion data (like ID)\n",
    "    self._entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.append(test_model)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "test_eq(len(dataset), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def pop(self: Dataset, index: int = -1) -> BaseModelType:\n",
    "    \"\"\"Remove and return entry at index, sync deletion to Notion.\"\"\"\n",
    "    entry = self._entries[index]\n",
    "    # get the row id\n",
    "    row_id = entry._row_id\n",
    "    if row_id is None:\n",
    "        raise ValueError(\"Entry has no row id. This likely means it was not added or synced to the dataset.\")\n",
    "\n",
    "    # soft delete the row\n",
    "    sync_func = async_to_sync(self._ragas_api_client.delete_dataset_row)\n",
    "    sync_func(project_id=self.project_id, dataset_id=self.dataset_id, row_id=row_id)\n",
    "\n",
    "    # Remove from local cache\n",
    "    return self._entries.pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.pop()\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "test_eq(len(dataset), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now add some more entries\n",
    "for i in range(10):\n",
    "    dataset.append(test_model)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def load(self: Dataset) -> None:\n",
    "    \"\"\"Load all entries from the backend API.\"\"\"\n",
    "    # Get all rows\n",
    "    sync_func = async_to_sync(self._ragas_api_client.list_dataset_rows)\n",
    "    response = sync_func(\n",
    "        project_id=self.project_id,\n",
    "        dataset_id=self.dataset_id\n",
    "    )\n",
    "    \n",
    "    # Get column mapping (ID -> name)\n",
    "    column_map = {v: k for k, v in self.model.__column_mapping__.items()}\n",
    "    \n",
    "    # Clear existing entries\n",
    "    self._entries.clear()\n",
    "    \n",
    "    # Process rows\n",
    "    for row in response.get(\"items\", []):\n",
    "        model_data = {}\n",
    "        row_id = row.get(\"id\")\n",
    "        \n",
    "        # Convert from API data format to model fields\n",
    "        for col_id, value in row.get(\"data\", {}).items():\n",
    "            if col_id in column_map:\n",
    "                field_name = column_map[col_id]\n",
    "                model_data[field_name] = value\n",
    "        \n",
    "        # Create model instance\n",
    "        entry = self.model(**model_data)\n",
    "        \n",
    "        # Store row ID for future operations\n",
    "        entry._row_id = row_id\n",
    "        \n",
    "        self._entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def load_as_dicts(self: Dataset) -> t.List[t.Dict]:\n",
    "    \"\"\"Load all entries as dictionaries.\"\"\"\n",
    "    # Get all rows\n",
    "    sync_func = async_to_sync(self._ragas_api_client.list_dataset_rows)\n",
    "    response = sync_func(\n",
    "        project_id=self.project_id,\n",
    "        dataset_id=self.dataset_id\n",
    "    )\n",
    "    \n",
    "    # Get column mapping (ID -> name)\n",
    "    column_map = {v: k for k, v in self.model.__column_mapping__.items()}\n",
    "    \n",
    "    # Convert to dicts with field names\n",
    "    result = []\n",
    "    for row in response.get(\"items\", []):\n",
    "        item_dict = {}\n",
    "        for col_id, value in row.get(\"data\", {}).items():\n",
    "            if col_id in column_map:\n",
    "                field_name = column_map[col_id]\n",
    "                item_dict[field_name] = value\n",
    "        result.append(item_dict)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.load_as_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def to_pandas(self: Dataset) -> \"pd.DataFrame\":\n",
    "    \"\"\"Convert dataset to pandas DataFrame.\"\"\"\n",
    "\n",
    "    # Make sure we have data\n",
    "    if not self._entries:\n",
    "        self.load()\n",
    "    \n",
    "    # Convert entries to dictionaries\n",
    "    data = [entry.model_dump() for entry in self._entries]\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>test description</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  name       description result\n",
       "0    0  test  test description    0.5\n",
       "1    0  test  test description    0.5\n",
       "2    0  test  test description    0.5\n",
       "3    0  test  test description    0.5\n",
       "4    0  test  test description    0.5\n",
       "5    0  test  test description    0.5\n",
       "6    0  test  test description    0.5\n",
       "7    0  test  test description    0.5\n",
       "8    0  test  test description    0.5\n",
       "9    0  test  test description    0.5\n",
       "10   0  test  test description    0.5\n",
       "11   0  test  test description    0.5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def save(self: Dataset, item: BaseModelType) -> None:\n",
    "    \"\"\"Save changes to an item to the backend.\"\"\"\n",
    "    if not isinstance(item, self.model):\n",
    "        raise TypeError(f\"Item must be an instance of {self.model.__name__}\")\n",
    "    \n",
    "    # Get the row ID\n",
    "    row_id = None\n",
    "    if hasattr(item, \"_row_id\") and item._row_id:\n",
    "        row_id = item._row_id\n",
    "    else:\n",
    "        # Try to find it in our entries by matching\n",
    "        for i, entry in enumerate(self._entries):\n",
    "            if id(entry) == id(item):  # Check if it's the same object\n",
    "                if hasattr(entry, \"_row_id\") and entry._row_id:\n",
    "                    row_id = entry._row_id\n",
    "                    break\n",
    "    \n",
    "    if not row_id:\n",
    "        raise ValueError(\"Cannot save: item is not from this dataset or was not properly synced\")\n",
    "    \n",
    "    # Get column mapping and prepare data\n",
    "    column_id_map = self.model.__column_mapping__\n",
    "    row_dict = rt.ModelConverter.instance_to_row(item)[\"data\"]\n",
    "    row_data = {}\n",
    "    \n",
    "    for column in row_dict:\n",
    "        if column[\"column_id\"] in column_id_map:\n",
    "            row_data[column_id_map[column[\"column_id\"]]] = column[\"data\"]\n",
    "    \n",
    "    # Update in backend\n",
    "    sync_func = async_to_sync(self._ragas_api_client.update_dataset_row)\n",
    "    response = sync_func(\n",
    "        project_id=self.project_id,\n",
    "        dataset_id=self.dataset_id,\n",
    "        row_id=row_id,\n",
    "        data=row_data,\n",
    "    )\n",
    "    \n",
    "    # Find and update in local cache if needed\n",
    "    for i, entry in enumerate(self._entries):\n",
    "        if hasattr(entry, \"_row_id\") and entry._row_id == row_id:\n",
    "            # If it's not the same object, update our copy\n",
    "            if id(entry) != id(item):\n",
    "                self._entries[i] = item\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestModel(id=0, name='updated name', description='test description', result=0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dataset[0]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'updated name'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.name = \"updated name\"\n",
    "dataset.save(d)\n",
    "dataset[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'test',\n",
       "  'id': 0},\n",
       " {'description': 'test description',\n",
       "  'result': 0.5,\n",
       "  'result_reason': 'test reason',\n",
       "  'name': 'updated name',\n",
       "  'id': 0}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.load_as_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def get(self: Dataset, field_value: str, field_name: str = \"_row_id\") -> t.Optional[BaseModelType]:\n",
    "    \"\"\"Get an entry by field value.\n",
    "    \n",
    "    Args:\n",
    "        id_value: The value to match\n",
    "        field_name: The field to match against (default: \"id\")\n",
    "        \n",
    "    Returns:\n",
    "        The matching model instance or None if not found\n",
    "    \"\"\"\n",
    "    # Check if we need to load entries\n",
    "    if not self._entries:\n",
    "        self.load()\n",
    "    \n",
    "    # Search in local entries first\n",
    "    for entry in self._entries:\n",
    "        if hasattr(entry, field_name) and getattr(entry, field_name) == field_value:\n",
    "            return entry\n",
    "    \n",
    "    # If not found and field is \"id\", try to get directly from API\n",
    "    if field_name == \"id\":\n",
    "        # Get column ID for field\n",
    "        if field_name not in self.model.__column_mapping__:\n",
    "            return None\n",
    "        \n",
    "        column_id = self.model.__column_mapping__[field_name]\n",
    "        \n",
    "        # Get rows with filter\n",
    "        sync_func = async_to_sync(self._ragas_api_client.list_dataset_rows)\n",
    "        response = sync_func(\n",
    "            project_id=self.project_id,\n",
    "            dataset_id=self.dataset_id,\n",
    "            # We don't have direct filter support in the API client,\n",
    "            # so this would need to be implemented there.\n",
    "            # For now, we've already checked our local cache.\n",
    "        )\n",
    "        \n",
    "        # Would parse response here if we had filtering\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eVpgxsmPGwa8'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d._row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestModel(id=0, name='updated name', description='test description', result=0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = dataset.get(d._row_id)\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
