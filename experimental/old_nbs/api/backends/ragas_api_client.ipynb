{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas API Client\n",
    "\n",
    "> Python client to api.ragas.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp backends.ragas_api_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAGAS_APP_TOKEN = \"api_key\"\n",
    "RAGAS_API_ENDPOINT = \"https://api.dev.app.ragas.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import httpx\n",
    "import asyncio\n",
    "import typing as t\n",
    "from pydantic import BaseModel, Field\n",
    "from fastcore.utils import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ragas_experimental.exceptions import (\n",
    "    DatasetNotFoundError, DuplicateDatasetError,\n",
    "    ProjectNotFoundError, DuplicateProjectError,\n",
    "    ExperimentNotFoundError, DuplicateExperimentError\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RagasApiClient():\n",
    "    \"\"\"Client for the Ragas Relay API.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str, app_token: t.Optional[str] = None):\n",
    "        \"\"\"Initialize the Ragas API client.\n",
    "        \n",
    "        Args:\n",
    "            base_url: Base URL for the API (e.g., \"http://localhost:8087\")\n",
    "            app_token: API token for authentication\n",
    "        \"\"\"\n",
    "        if not app_token:\n",
    "            raise ValueError(\"app_token must be provided\")\n",
    "\n",
    "        self.base_url = f\"{base_url.rstrip('/')}/api/v1\"\n",
    "        self.app_token = app_token\n",
    "\n",
    "    async def _request(\n",
    "        self,\n",
    "        method: str,\n",
    "        endpoint: str,\n",
    "        params: t.Optional[t.Dict] = None,\n",
    "        json_data: t.Optional[t.Dict] = None,\n",
    "    ) -> t.Dict:\n",
    "        \"\"\"Make a request to the API.\n",
    "        \n",
    "        Args:\n",
    "            method: HTTP method (GET, POST, PATCH, DELETE)\n",
    "            endpoint: API endpoint path\n",
    "            params: Query parameters\n",
    "            json_data: JSON request body\n",
    "            \n",
    "        Returns:\n",
    "            The response data from the API\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/{endpoint.lstrip('/')}\"\n",
    "        headers = {\"X-App-Token\": self.app_token}\n",
    "\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.request(\n",
    "                method=method, url=url, params=params, json=json_data, headers=headers\n",
    "            )\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            if response.status_code >= 400 or data.get(\"status\") == \"error\":\n",
    "                error_msg = data.get(\"message\", \"Unknown error\")\n",
    "                raise Exception(f\"API Error ({response.status_code}): {error_msg}\")\n",
    "\n",
    "            return data.get(\"data\")\n",
    "\n",
    "    #---- Resource Handlers ----\n",
    "    async def _create_resource(self, path, data):\n",
    "        \"\"\"Generic resource creation.\"\"\"\n",
    "        return await self._request(\"POST\", path, json_data=data)\n",
    "        \n",
    "    async def _list_resources(self, path, **params):\n",
    "        \"\"\"Generic resource listing.\"\"\"\n",
    "        return await self._request(\"GET\", path, params=params)\n",
    "        \n",
    "    async def _get_resource(self, path):\n",
    "        \"\"\"Generic resource retrieval.\"\"\"\n",
    "        return await self._request(\"GET\", path)\n",
    "        \n",
    "    async def _update_resource(self, path, data):\n",
    "        \"\"\"Generic resource update.\"\"\"\n",
    "        return await self._request(\"PATCH\", path, json_data=data)\n",
    "        \n",
    "    async def _delete_resource(self, path):\n",
    "        \"\"\"Generic resource deletion.\"\"\"\n",
    "        return await self._request(\"DELETE\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def _get_resource_by_name(\n",
    "    self: RagasApiClient,\n",
    "    list_method: t.Callable,\n",
    "    get_method: t.Callable,\n",
    "    resource_name: str,\n",
    "    name_field: str,\n",
    "    not_found_error: t.Type[Exception],\n",
    "    duplicate_error: t.Type[Exception],\n",
    "    resource_type_name: str,\n",
    "    **list_method_kwargs\n",
    ") -> t.Dict:\n",
    "    \"\"\"Generic method to get a resource by name.\n",
    "    \n",
    "    Args:\n",
    "        list_method: Method to list resources\n",
    "        get_method: Method to get a specific resource\n",
    "        resource_name: Name to search for\n",
    "        name_field: Field name that contains the resource name\n",
    "        not_found_error: Exception to raise when resource is not found\n",
    "        duplicate_error: Exception to raise when multiple resources are found\n",
    "        resource_type_name: Human-readable name of the resource type\n",
    "        **list_method_kwargs: Additional arguments to pass to list_method\n",
    "        \n",
    "    Returns:\n",
    "        The resource information dictionary\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If resource is not found or multiple resources are found\n",
    "    \"\"\"\n",
    "    # Initial pagination parameters\n",
    "    limit = 50  # Number of items per page\n",
    "    offset = 0  # Starting position\n",
    "    matching_resources = []\n",
    "    \n",
    "    while True:\n",
    "        # Get a page of resources\n",
    "        response = await list_method(\n",
    "            limit=limit,\n",
    "            offset=offset,\n",
    "            **list_method_kwargs\n",
    "        )\n",
    "        \n",
    "        items = response.get(\"items\", [])\n",
    "        \n",
    "        # If no items returned, we've reached the end\n",
    "        if not items:\n",
    "            break\n",
    "            \n",
    "        # Collect all resources with the matching name in this page\n",
    "        for resource in items:\n",
    "            if resource.get(name_field) == resource_name:\n",
    "                matching_resources.append(resource)\n",
    "        \n",
    "        # Update offset for the next page\n",
    "        offset += limit\n",
    "        \n",
    "        # If we've processed all items (less than limit returned), exit the loop\n",
    "        if len(items) < limit:\n",
    "            break\n",
    "    \n",
    "    # Check results\n",
    "    if not matching_resources:\n",
    "        context = list_method_kwargs.get(\"project_id\", \"\")\n",
    "        context_msg = f\" in project {context}\" if context else \"\"\n",
    "        raise not_found_error(\n",
    "            f\"No {resource_type_name} with name '{resource_name}' found{context_msg}\"\n",
    "        )\n",
    "    \n",
    "    if len(matching_resources) > 1:\n",
    "        # Multiple matches found - construct an informative error message\n",
    "        resource_ids = [r.get(\"id\") for r in matching_resources]\n",
    "        context = list_method_kwargs.get(\"project_id\", \"\")\n",
    "        context_msg = f\" in project {context}\" if context else \"\"\n",
    "        \n",
    "        raise duplicate_error(\n",
    "            f\"Multiple {resource_type_name}s found with name '{resource_name}'{context_msg}. \"\n",
    "            f\"{resource_type_name.capitalize()} IDs: {', '.join(resource_ids)}. \"\n",
    "            f\"Please use get_{resource_type_name}() with a specific ID instead.\"\n",
    "        )\n",
    "    \n",
    "    # Exactly one match found - retrieve full details\n",
    "    if \"project_id\" in list_method_kwargs:\n",
    "        return await get_method(list_method_kwargs[\"project_id\"], matching_resources[0].get(\"id\"))\n",
    "    else:\n",
    "        return await get_method(matching_resources[0].get(\"id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Projects ----\n",
    "@patch\n",
    "async def list_projects(\n",
    "    self: RagasApiClient,\n",
    "    ids: t.Optional[t.List[str]] = None,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List projects.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "\n",
    "    if ids:\n",
    "        params[\"ids\"] = \",\".join(ids)\n",
    "\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "\n",
    "    return await self._list_resources(\"projects\", **params)\n",
    "\n",
    "@patch\n",
    "async def get_project(self: RagasApiClient, project_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific project by ID.\"\"\"\n",
    "    # TODO: Need get project by title\n",
    "    return await self._get_resource(f\"projects/{project_id}\")\n",
    "\n",
    "@patch\n",
    "async def create_project(\n",
    "    self: RagasApiClient, title: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new project.\"\"\"\n",
    "    data = {\"title\": title}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._create_resource(\"projects\", data)\n",
    "\n",
    "@patch\n",
    "async def update_project(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    title: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing project.\"\"\"\n",
    "    data = {}\n",
    "    if title:\n",
    "        data[\"title\"] = title\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._update_resource(f\"projects/{project_id}\", data)\n",
    "\n",
    "@patch\n",
    "async def delete_project(self: RagasApiClient, project_id: str) -> None:\n",
    "    \"\"\"Delete a project.\"\"\"\n",
    "    await self._delete_resource(f\"projects/{project_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 projects:\n",
      "Error: string indices must be integers, not 'str'\n"
     ]
    }
   ],
   "source": [
    "# Initialize client with your authentication token\n",
    "client = RagasApiClient(base_url=RAGAS_API_ENDPOINT, app_token=RAGAS_APP_TOKEN)\n",
    "\n",
    "# List projects\n",
    "try:\n",
    "    projects = await client.list_projects(limit=10)\n",
    "    print(f\"Found {len(projects)} projects:\")\n",
    "    for project in projects:\n",
    "        print(f\"- {project['title']} (ID: {project['id']})\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '26b0e577-8ff8-4014-bc7a-cfc410df3488',\n",
       " 'title': 'test project',\n",
       " 'description': 'test description',\n",
       " 'created_at': '2025-04-10T00:12:34.606398+00:00',\n",
       " 'updated_at': '2025-04-10T00:12:34.606398+00:00'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_project(\"test project\", \"test description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': '1ef0843b-231f-4a2c-b64d-d39bcee9d830',\n",
       "   'title': 'yann-lecun-wisdom',\n",
       "   'description': 'Yann LeCun Wisdom',\n",
       "   'created_at': '2025-04-15T03:27:08.962384+00:00',\n",
       "   'updated_at': '2025-04-15T03:27:08.962384+00:00'},\n",
       "  {'id': 'c2d788ec-a602-495b-8ddc-f457ce11b414',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-12T19:47:10.928422+00:00',\n",
       "   'updated_at': '2025-04-12T19:47:10.928422+00:00'},\n",
       "  {'id': '0d465f02-c88f-454e-9ff3-780a001e3e21',\n",
       "   'title': 'test project',\n",
       "   'description': 'test description',\n",
       "   'created_at': '2025-04-12T19:46:36.221385+00:00',\n",
       "   'updated_at': '2025-04-12T19:46:36.221385+00:00'},\n",
       "  {'id': '2ae1434c-e700-44a7-9528-7c2f03cfb491',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-12T19:46:36.157122+00:00',\n",
       "   'updated_at': '2025-04-12T19:46:36.157122+00:00'},\n",
       "  {'id': 'adb45ec6-6902-4339-b05f-3b86fd256c7e',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-12T19:45:54.430913+00:00',\n",
       "   'updated_at': '2025-04-12T19:45:54.430913+00:00'},\n",
       "  {'id': '6f26bf5b-af4d-48b5-af2d-13d3e671bbbf',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:56:30.085249+00:00',\n",
       "   'updated_at': '2025-04-11T00:56:30.085249+00:00'},\n",
       "  {'id': '63e4fc0f-1a60-441b-bd71-f21ce8e35c7e',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:44:56.031721+00:00',\n",
       "   'updated_at': '2025-04-11T00:44:56.031721+00:00'},\n",
       "  {'id': 'db0bedd6-6cfa-4551-b1ab-af78fa82dca7',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:44:17.601598+00:00',\n",
       "   'updated_at': '2025-04-11T00:44:17.601598+00:00'},\n",
       "  {'id': '80c8ef9a-23d7-4a9f-a7d7-36c6472ab51e',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:42:37.287184+00:00',\n",
       "   'updated_at': '2025-04-11T00:42:37.287184+00:00'},\n",
       "  {'id': 'ae2a5a5c-3902-4ef6-af50-f2d8f27feea6',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:40:53.71528+00:00',\n",
       "   'updated_at': '2025-04-11T00:40:53.71528+00:00'},\n",
       "  {'id': '96618f8b-d3a1-4998-9a66-155f8f254512',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:31:21.410658+00:00',\n",
       "   'updated_at': '2025-04-11T00:31:21.410658+00:00'},\n",
       "  {'id': '4515aa23-cb4c-4c0a-b833-fefd0a30fdcc',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:27:49.977435+00:00',\n",
       "   'updated_at': '2025-04-11T00:27:49.977435+00:00'},\n",
       "  {'id': '138098a4-651e-4dca-b226-d70956b3e039',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-11T00:24:03.39505+00:00',\n",
       "   'updated_at': '2025-04-11T00:24:03.39505+00:00'},\n",
       "  {'id': 'bbe45632-3268-43a6-9694-b020b3f5226f',\n",
       "   'title': 'Demo Project',\n",
       "   'description': None,\n",
       "   'created_at': '2025-04-10T22:41:14.663646+00:00',\n",
       "   'updated_at': '2025-04-10T22:41:14.663646+00:00'},\n",
       "  {'id': 'df764139-bac7-4aec-af24-5c6886189f84',\n",
       "   'title': 'SuperMe-Demo',\n",
       "   'description': 'SuperMe demo to show the team',\n",
       "   'created_at': '2025-04-10T04:35:18.631257+00:00',\n",
       "   'updated_at': '2025-04-10T04:35:18.631257+00:00'},\n",
       "  {'id': 'a6ccabe0-7b8d-4866-98af-f167a36b94ff',\n",
       "   'title': 'SuperMe',\n",
       "   'description': 'SuperMe demo to show the team',\n",
       "   'created_at': '2025-04-10T03:10:29.153622+00:00',\n",
       "   'updated_at': '2025-04-10T03:10:29.153622+00:00'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 16,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'desc'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_projects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PROJECT_ID = \"a6ccabe0-7b8d-4866-98af-f167a36b94ff\"\n",
    "project = await client.get_project(TEST_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def get_project_by_name(\n",
    "    self: RagasApiClient, project_name: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a project by its name.\n",
    "    \n",
    "    Args:\n",
    "        project_name: Name of the project to find\n",
    "        \n",
    "    Returns:\n",
    "        The project information dictionary\n",
    "        \n",
    "    Raises:\n",
    "        ProjectNotFoundError: If no project with the given name is found\n",
    "        DuplicateProjectError: If multiple projects with the given name are found\n",
    "    \"\"\"\n",
    "    return await self._get_resource_by_name(\n",
    "        list_method=self.list_projects,\n",
    "        get_method=self.get_project,\n",
    "        resource_name=project_name,\n",
    "        name_field=\"title\",  # Projects use 'title' instead of 'name'\n",
    "        not_found_error=ProjectNotFoundError,\n",
    "        duplicate_error=DuplicateProjectError,\n",
    "        resource_type_name=\"project\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'a6ccabe0-7b8d-4866-98af-f167a36b94ff',\n",
       " 'title': 'SuperMe',\n",
       " 'description': 'SuperMe demo to show the team',\n",
       " 'created_at': '2025-04-10T03:10:29.153622+00:00',\n",
       " 'updated_at': '2025-04-10T03:10:29.153622+00:00'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.get_project_by_name(\"SuperMe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#---- Datasets ----\n",
    "@patch\n",
    "async def list_datasets(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List datasets in a project.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(f\"projects/{project_id}/datasets\", **params)\n",
    "\n",
    "@patch\n",
    "async def get_dataset(self: RagasApiClient, project_id: str, dataset_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific dataset.\"\"\"\n",
    "    return await self._get_resource(f\"projects/{project_id}/datasets/{dataset_id}\")\n",
    "\n",
    "@patch\n",
    "async def create_dataset(\n",
    "    self: RagasApiClient, project_id: str, name: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new dataset in a project.\"\"\"\n",
    "    data = {\"name\": name}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._create_resource(f\"projects/{project_id}/datasets\", data)\n",
    "\n",
    "@patch\n",
    "async def update_dataset(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    name: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing dataset.\"\"\"\n",
    "    data = {}\n",
    "    if name:\n",
    "        data[\"name\"] = name\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._update_resource(f\"projects/{project_id}/datasets/{dataset_id}\", data)\n",
    "\n",
    "@patch\n",
    "async def delete_dataset(self: RagasApiClient, project_id: str, dataset_id: str) -> None:\n",
    "    \"\"\"Delete a dataset.\"\"\"\n",
    "    await self._delete_resource(f\"projects/{project_id}/datasets/{dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1ef0843b-231f-4a2c-b64d-d39bcee9d830',\n",
       " 'a6ccabe0-7b8d-4866-98af-f167a36b94ff')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check project ID\n",
    "projects = await client.list_projects()\n",
    "projects[\"items\"][0][\"id\"], TEST_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset created: {'id': '2382037f-906c-45a0-9b9f-702d32903efd', 'name': 'New Dataset', 'description': 'This is a new dataset', 'updated_at': '2025-04-16T03:52:01.91574+00:00', 'created_at': '2025-04-16T03:52:01.91574+00:00', 'version_counter': 0, 'project_id': '1ef0843b-231f-4a2c-b64d-d39bcee9d830'}\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "new_dataset = await client.create_dataset(\n",
    "    projects[\"items\"][0][\"id\"], \"New Dataset\", \"This is a new dataset\"\n",
    ")\n",
    "print(f\"New dataset created: {new_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 datasets\n"
     ]
    }
   ],
   "source": [
    "# List datasets in the project\n",
    "datasets = await client.list_datasets(projects[\"items\"][0][\"id\"])\n",
    "print(f\"Found {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset: {'id': '8572180f-fddf-46c5-b943-e6ff6448eb01', 'name': 'Updated Dataset', 'description': 'This is an updated dataset', 'created_at': '2025-04-15T03:28:09.050125+00:00', 'updated_at': '2025-04-16T03:52:09.627448+00:00', 'version_counter': 0, 'project_id': '1ef0843b-231f-4a2c-b64d-d39bcee9d830'}\n"
     ]
    }
   ],
   "source": [
    "updated_dataset = await client.update_dataset(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"items\"][0][\"id\"],\n",
    "    \"Updated Dataset\",\n",
    "    \"This is an updated dataset\",\n",
    ")\n",
    "print(f\"Updated dataset: {updated_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete the dataset\n",
    "await client.delete_dataset(projects[\"items\"][0][\"id\"], datasets[\"items\"][0][\"id\"])\n",
    "print(\"Dataset deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time being I've also added another option to get the dataset by name too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def get_dataset_by_name(\n",
    "    self: RagasApiClient, project_id: str, dataset_name: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a dataset by its name.\n",
    "    \n",
    "    Args:\n",
    "        project_id: ID of the project\n",
    "        dataset_name: Name of the dataset to find\n",
    "        \n",
    "    Returns:\n",
    "        The dataset information dictionary\n",
    "        \n",
    "    Raises:\n",
    "        DatasetNotFoundError: If no dataset with the given name is found\n",
    "        DuplicateDatasetError: If multiple datasets with the given name are found\n",
    "    \"\"\"\n",
    "    return await self._get_resource_by_name(\n",
    "        list_method=self.list_datasets,\n",
    "        get_method=self.get_dataset,\n",
    "        resource_name=dataset_name,\n",
    "        name_field=\"name\",\n",
    "        not_found_error=DatasetNotFoundError,\n",
    "        duplicate_error=DuplicateDatasetError,\n",
    "        resource_type_name=\"dataset\",\n",
    "        project_id=project_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateDatasetError",
     "evalue": "Multiple datasets found with name 'test' in project a6ccabe0-7b8d-4866-98af-f167a36b94ff. Dataset IDs: 9a48d5d1-531f-424f-b2d2-d8f9bcaeec1e, 483477a4-3d00-4010-a253-c92dee3bc092. Please use get_dataset() with a specific ID instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDuplicateDatasetError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client.get_dataset_by_name(project_id=TEST_PROJECT_ID, dataset_name=\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mget_dataset_by_name\u001b[39m\u001b[34m(self, project_id, dataset_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@patch\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dataset_by_name\u001b[39m(\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mself\u001b[39m: RagasApiClient, project_id: \u001b[38;5;28mstr\u001b[39m, dataset_name: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m      4\u001b[39m ) -> t.Dict:\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a dataset by its name.\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m        DuplicateDatasetError: If multiple datasets with the given name are found\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_resource_by_name(\n\u001b[32m     19\u001b[39m         list_method=\u001b[38;5;28mself\u001b[39m.list_datasets,\n\u001b[32m     20\u001b[39m         get_method=\u001b[38;5;28mself\u001b[39m.get_dataset,\n\u001b[32m     21\u001b[39m         resource_name=dataset_name,\n\u001b[32m     22\u001b[39m         name_field=\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m         not_found_error=DatasetNotFoundError,\n\u001b[32m     24\u001b[39m         duplicate_error=DuplicateDatasetError,\n\u001b[32m     25\u001b[39m         resource_type_name=\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m         project_id=project_id\n\u001b[32m     27\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m_get_resource_by_name\u001b[39m\u001b[34m(self, list_method, get_method, resource_name, name_field, not_found_error, duplicate_error, resource_type_name, **list_method_kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m     context = list_method_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     74\u001b[39m     context_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m in project \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m duplicate_error(\n\u001b[32m     77\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMultiple \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms found with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_type_name.capitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(resource_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease use get_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() with a specific ID instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m     )\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Exactly one match found - retrieve full details\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m list_method_kwargs:\n",
      "\u001b[31mDuplicateDatasetError\u001b[39m: Multiple datasets found with name 'test' in project a6ccabe0-7b8d-4866-98af-f167a36b94ff. Dataset IDs: 9a48d5d1-531f-424f-b2d2-d8f9bcaeec1e, 483477a4-3d00-4010-a253-c92dee3bc092. Please use get_dataset() with a specific ID instead."
     ]
    }
   ],
   "source": [
    "await client.get_dataset_by_name(project_id=TEST_PROJECT_ID, dataset_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "#---- Experiments ----\n",
    "@patch\n",
    "async def list_experiments(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List experiments in a project.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(f\"projects/{project_id}/experiments\", **params)\n",
    "\n",
    "@patch\n",
    "async def get_experiment(self: RagasApiClient, project_id: str, experiment_id: str) -> t.Dict:\n",
    "    \"\"\"Get a specific experiment.\"\"\"\n",
    "    return await self._get_resource(f\"projects/{project_id}/experiments/{experiment_id}\")\n",
    "\n",
    "@patch\n",
    "async def create_experiment(\n",
    "    self: RagasApiClient, project_id: str, name: str, description: t.Optional[str] = None\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new experiment in a project.\"\"\"\n",
    "    data = {\"name\": name}\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._create_resource(f\"projects/{project_id}/experiments\", data)\n",
    "\n",
    "@patch\n",
    "async def update_experiment(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    name: t.Optional[str] = None,\n",
    "    description: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing experiment.\"\"\"\n",
    "    data = {}\n",
    "    if name:\n",
    "        data[\"name\"] = name\n",
    "    if description:\n",
    "        data[\"description\"] = description\n",
    "    return await self._update_resource(f\"projects/{project_id}/experiments/{experiment_id}\", data)\n",
    "\n",
    "@patch\n",
    "async def delete_experiment(self: RagasApiClient, project_id: str, experiment_id: str) -> None:\n",
    "    \"\"\"Delete an experiment.\"\"\"\n",
    "    await self._delete_resource(f\"projects/{project_id}/experiments/{experiment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New experiment created: {'id': 'b575c5d1-6934-45c0-b67a-fc9a4d7bdba3', 'name': 'New Experiment', 'description': 'This is a new experiment', 'updated_at': '2025-04-10T00:12:39.955229+00:00', 'created_at': '2025-04-10T00:12:39.955229+00:00', 'version_counter': 0, 'project_id': '26b0e577-8ff8-4014-bc7a-cfc410df3488'}\n",
      "Found 2 experiments\n",
      "Experiment: {'id': 'b575c5d1-6934-45c0-b67a-fc9a4d7bdba3', 'name': 'New Experiment', 'description': 'This is a new experiment', 'created_at': '2025-04-10T00:12:39.955229+00:00', 'updated_at': '2025-04-10T00:12:39.955229+00:00', 'version_counter': 0, 'project_id': '26b0e577-8ff8-4014-bc7a-cfc410df3488'}\n",
      "Updated experiment: {'id': 'b575c5d1-6934-45c0-b67a-fc9a4d7bdba3', 'name': 'Updated Experiment', 'description': 'This is an updated experiment', 'created_at': '2025-04-10T00:12:39.955229+00:00', 'updated_at': '2025-04-10T00:12:41.676216+00:00', 'version_counter': 0, 'project_id': '26b0e577-8ff8-4014-bc7a-cfc410df3488'}\n",
      "Experiment deleted\n"
     ]
    }
   ],
   "source": [
    "# create a new experiment\n",
    "new_experiment = await client.create_experiment(\n",
    "    projects[\"items\"][0][\"id\"], \"New Experiment\", \"This is a new experiment\"\n",
    ")\n",
    "print(f\"New experiment created: {new_experiment}\")\n",
    "# list experiments\n",
    "experiments = await client.list_experiments(projects[\"items\"][0][\"id\"])\n",
    "print(f\"Found {len(experiments)} experiments\")\n",
    "# get a specific experiment\n",
    "experiment = await client.get_experiment(\n",
    "    projects[\"items\"][0][\"id\"], experiments[\"items\"][0][\"id\"]\n",
    ")\n",
    "print(f\"Experiment: {experiment}\")\n",
    "# update an experiment\n",
    "updated_experiment = await client.update_experiment(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    experiments[\"items\"][0][\"id\"],\n",
    "    \"Updated Experiment\",\n",
    "    \"This is an updated experiment\",\n",
    ")\n",
    "print(f\"Updated experiment: {updated_experiment}\")\n",
    "# delete an experiment\n",
    "await client.delete_experiment(projects[\"items\"][0][\"id\"], experiments[\"items\"][0][\"id\"])\n",
    "print(\"Experiment deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': '78fd6c58-7edf-4239-93d1-4f49185d8e49',\n",
       "   'name': 'New Experiment',\n",
       "   'description': 'This is a new experiment',\n",
       "   'created_at': '2025-03-30T06:31:31.689269+00:00',\n",
       "   'updated_at': '2025-03-30T06:31:31.689269+00:00',\n",
       "   'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'},\n",
       "  {'id': '7c695b58-7fc3-464c-a18b-a96e35f9684d',\n",
       "   'name': 'New Experiment',\n",
       "   'description': 'This is a new experiment',\n",
       "   'created_at': '2025-04-09T17:03:44.340782+00:00',\n",
       "   'updated_at': '2025-04-09T17:03:44.340782+00:00',\n",
       "   'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 2,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_experiments(TEST_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def get_experiment_by_name(\n",
    "    self: RagasApiClient, project_id: str, experiment_name: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get an experiment by its name.\n",
    "    \n",
    "    Args:\n",
    "        project_id: ID of the project containing the experiment\n",
    "        experiment_name: Name of the experiment to find\n",
    "        \n",
    "    Returns:\n",
    "        The experiment information dictionary\n",
    "        \n",
    "    Raises:\n",
    "        ExperimentNotFoundError: If no experiment with the given name is found\n",
    "        DuplicateExperimentError: If multiple experiments with the given name are found\n",
    "    \"\"\"\n",
    "    return await self._get_resource_by_name(\n",
    "        list_method=self.list_experiments,\n",
    "        get_method=self.get_experiment,\n",
    "        resource_name=experiment_name,\n",
    "        name_field=\"name\",\n",
    "        not_found_error=ExperimentNotFoundError,\n",
    "        duplicate_error=DuplicateExperimentError,\n",
    "        resource_type_name=\"experiment\",\n",
    "        project_id=project_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateExperimentError",
     "evalue": "Multiple experiments found with name 'test' in project a6ccabe0-7b8d-4866-98af-f167a36b94ff. Experiment IDs: e1ae15aa-2e0e-40dd-902a-0f0e0fd4df69, 52428c79-afdf-468e-82dc-6ef82c5b71d2, 55e14ac3-0037-4909-898f-eee9533a6d3f, 9adfa008-b479-41cf-ba28-c860e01401ea, 233d28c8-6556-49c5-b146-1e001720c214, 6aed5143-3f60-4bf2-bcf2-ecfdb950e992. Please use get_experiment() with a specific ID instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDuplicateExperimentError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client.get_experiment_by_name(TEST_PROJECT_ID, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mget_experiment_by_name\u001b[39m\u001b[34m(self, project_id, experiment_name)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;129m@patch\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_experiment_by_name\u001b[39m(\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mself\u001b[39m: RagasApiClient, project_id: \u001b[38;5;28mstr\u001b[39m, experiment_name: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m      5\u001b[39m ) -> t.Dict:\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get an experiment by its name.\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \u001b[33;03m        DuplicateExperimentError: If multiple experiments with the given name are found\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_resource_by_name(\n\u001b[32m     20\u001b[39m         list_method=\u001b[38;5;28mself\u001b[39m.list_experiments,\n\u001b[32m     21\u001b[39m         get_method=\u001b[38;5;28mself\u001b[39m.get_experiment,\n\u001b[32m     22\u001b[39m         resource_name=experiment_name,\n\u001b[32m     23\u001b[39m         name_field=\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m         not_found_error=ExperimentNotFoundError,\n\u001b[32m     25\u001b[39m         duplicate_error=DuplicateExperimentError,\n\u001b[32m     26\u001b[39m         resource_type_name=\u001b[33m\"\u001b[39m\u001b[33mexperiment\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m         project_id=project_id\n\u001b[32m     28\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m_get_resource_by_name\u001b[39m\u001b[34m(self, list_method, get_method, resource_name, name_field, not_found_error, duplicate_error, resource_type_name, **list_method_kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m     context = list_method_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     74\u001b[39m     context_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m in project \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m duplicate_error(\n\u001b[32m     77\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMultiple \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms found with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_type_name.capitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(resource_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease use get_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_type_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() with a specific ID instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m     )\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Exactly one match found - retrieve full details\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m list_method_kwargs:\n",
      "\u001b[31mDuplicateExperimentError\u001b[39m: Multiple experiments found with name 'test' in project a6ccabe0-7b8d-4866-98af-f167a36b94ff. Experiment IDs: e1ae15aa-2e0e-40dd-902a-0f0e0fd4df69, 52428c79-afdf-468e-82dc-6ef82c5b71d2, 55e14ac3-0037-4909-898f-eee9533a6d3f, 9adfa008-b479-41cf-ba28-c860e01401ea, 233d28c8-6556-49c5-b146-1e001720c214, 6aed5143-3f60-4bf2-bcf2-ecfdb950e992. Please use get_experiment() with a specific ID instead."
     ]
    }
   ],
   "source": [
    "await client.get_experiment_by_name(TEST_PROJECT_ID, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns (for datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from ragas_experimental.typing import ColumnType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "#---- Dataset Columns ----\n",
    "@patch\n",
    "async def list_dataset_columns(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List columns in a dataset.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_dataset_column(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, column_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific column in a dataset.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_dataset_column(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    id: str,\n",
    "    name: str,\n",
    "    type: str,\n",
    "    col_order: t.Optional[int] = None,\n",
    "    settings: t.Optional[t.Dict] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new column in a dataset.\"\"\"\n",
    "    data = {\"id\": id, \"name\": name, \"type\": type}\n",
    "    if col_order is not None:\n",
    "        data[\"col_order\"] = col_order\n",
    "    if settings:\n",
    "        data[\"settings\"] = settings\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns\", data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_dataset_column(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, column_id: str, **column_data\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing column in a dataset.\"\"\"\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\",\n",
    "        column_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_dataset_column(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, column_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a column from a dataset.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/columns/{column_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cc6794e1-3505-4d5c-b403-ca7e55142bbc',\n",
       " 'name': 'New Dataset for testing columns',\n",
       " 'description': 'This is a new dataset for testing columns',\n",
       " 'updated_at': '2025-04-16T18:05:53.249101+00:00',\n",
       " 'created_at': '2025-04-16T18:05:53.249101+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': '3d9b529b-c23f-4e87-8a26-dd1923749aa7'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = await client.create_dataset(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    \"New Dataset for testing columns\",\n",
    "    \"This is a new dataset for testing columns\",\n",
    ")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_5',\n",
       " 'name': 'New Column 5',\n",
       " 'type': 'select',\n",
       " 'settings': {'id': 'new_column_5',\n",
       "  'name': 'New Column 5',\n",
       "  'type': 'select',\n",
       "  'width': 255,\n",
       "  'options': [{'name': 'name', 'value': 'name'},\n",
       "   {'name': 'age', 'value': 'age'},\n",
       "   {'name': 'gender', 'value': 'gender'}],\n",
       "  'isVisible': True,\n",
       "  'isEditable': True},\n",
       " 'created_at': '2025-04-16T18:11:14.305975+00:00',\n",
       " 'updated_at': '2025-04-16T18:11:14.305975+00:00',\n",
       " 'datatable_id': 'cc6794e1-3505-4d5c-b403-ca7e55142bbc'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new column to the dataset\n",
    "new_column = await client.create_dataset_column(\n",
    "    project_id=projects[\"items\"][0][\"id\"],\n",
    "    dataset_id=datasets[\"id\"],\n",
    "    id=\"new_column_5\",\n",
    "    name=\"New Column 3\",\n",
    "    type=ColumnType.SELECT.value,\n",
    "    settings={\n",
    "        \"width\": 255,\n",
    "        \"isVisible\": True,\n",
    "        \"isEditable\": True,\n",
    "        \"options\": [\n",
    "            {\"name\": \"name\", \"color\": \"hsl(200, 100%, 50%)\", \"value\": \"name\"},\n",
    "            {\"name\": \"age\", \"color\": \"hsl(200, 100%, 50%)\", \"value\": \"age\"},\n",
    "            {\"name\": \"gender\", \"color\": \"hsl(200, 100%, 50%)\", \"value\": \"gender\"},\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'id': 'dQ7hCb1AUfog',\n",
       "   'name': 'tags_color_coded',\n",
       "   'type': 'select',\n",
       "   'settings': {'id': 'dQ7hCb1AUfog',\n",
       "    'name': 'tags_color_coded',\n",
       "    'type': 'select',\n",
       "    'width': 255,\n",
       "    'options': [{'name': 'red', 'color': 'hsl(0, 85%, 60%)', 'value': 'red'},\n",
       "     {'name': 'green', 'color': 'hsl(30, 85%, 60%)', 'value': 'green'},\n",
       "     {'name': 'blue', 'color': 'hsl(45, 85%, 60%)', 'value': 'blue'}],\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-04-16T19:00:39.936764+00:00',\n",
       "   'updated_at': '2025-04-16T19:00:39.936764+00:00',\n",
       "   'datatable_id': '271b8bc7-2d04-43b8-8960-ce20365f546b'},\n",
       "  {'id': 'eCAiMBRqm0Uc',\n",
       "   'name': 'id',\n",
       "   'type': 'number',\n",
       "   'settings': {'id': 'eCAiMBRqm0Uc',\n",
       "    'name': 'id',\n",
       "    'type': 'number',\n",
       "    'width': 255,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-04-16T19:00:39.971857+00:00',\n",
       "   'updated_at': '2025-04-16T19:00:39.971857+00:00',\n",
       "   'datatable_id': '271b8bc7-2d04-43b8-8960-ce20365f546b'},\n",
       "  {'id': 'fRegl7Ucx3Sp',\n",
       "   'name': 'description',\n",
       "   'type': 'longText',\n",
       "   'settings': {'id': 'fRegl7Ucx3Sp',\n",
       "    'name': 'description',\n",
       "    'type': 'longText',\n",
       "    'width': 255,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True,\n",
       "    'max_length': 1000},\n",
       "   'created_at': '2025-04-16T19:00:40.055047+00:00',\n",
       "   'updated_at': '2025-04-16T19:00:40.055047+00:00',\n",
       "   'datatable_id': '271b8bc7-2d04-43b8-8960-ce20365f546b'},\n",
       "  {'id': 'foebrzYhiu9x',\n",
       "   'name': 'tags',\n",
       "   'type': 'select',\n",
       "   'settings': {'id': 'foebrzYhiu9x',\n",
       "    'name': 'tags',\n",
       "    'type': 'select',\n",
       "    'width': 255,\n",
       "    'options': [{'name': 'tag1', 'color': 'hsl(0, 85%, 60%)', 'value': 'tag1'},\n",
       "     {'name': 'tag2', 'color': 'hsl(30, 85%, 60%)', 'value': 'tag2'},\n",
       "     {'name': 'tag3', 'color': 'hsl(45, 85%, 60%)', 'value': 'tag3'}],\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-04-16T19:00:40.084457+00:00',\n",
       "   'updated_at': '2025-04-16T19:00:40.084457+00:00',\n",
       "   'datatable_id': '271b8bc7-2d04-43b8-8960-ce20365f546b'},\n",
       "  {'id': 'ciAzRUhKct9c',\n",
       "   'name': 'name',\n",
       "   'type': 'longText',\n",
       "   'settings': {'id': 'ciAzRUhKct9c',\n",
       "    'name': 'name',\n",
       "    'type': 'longText',\n",
       "    'width': 255,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True,\n",
       "    'max_length': 1000},\n",
       "   'created_at': '2025-04-16T19:00:40.232989+00:00',\n",
       "   'updated_at': '2025-04-16T19:00:40.232989+00:00',\n",
       "   'datatable_id': '271b8bc7-2d04-43b8-8960-ce20365f546b'},\n",
       "  {'id': 'iAW5muBh9mc251p8-LqKz',\n",
       "   'name': 'url',\n",
       "   'type': 'url',\n",
       "   'settings': {'id': 'iAW5muBh9mc251p8-LqKz',\n",
       "    'name': 'url',\n",
       "    'type': 'url',\n",
       "    'width': 192,\n",
       "    'position': 5,\n",
       "    'isVisible': True,\n",
       "    'isEditable': True},\n",
       "   'created_at': '2025-04-16T20:13:09.418698+00:00',\n",
       "   'updated_at': '2025-04-16T20:13:16.914367+00:00',\n",
       "   'datatable_id': '271b8bc7-2d04-43b8-8960-ce20365f546b'}],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 6,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_dataset_columns(projects[\"items\"][0][\"id\"], \"271b8bc7-2d04-43b8-8960-ce20365f546b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3',\n",
       " 'type': 'text',\n",
       " 'settings': {'id': 'new_column_3',\n",
       "  'name': 'New Column 3',\n",
       "  'type': 'text',\n",
       "  'max_length': 255,\n",
       "  'is_required': True},\n",
       " 'created_at': '2025-04-10T02:22:07.300895+00:00',\n",
       " 'updated_at': '2025-04-10T02:22:07.300895+00:00',\n",
       " 'datatable_id': 'ebc3dd3e-f88b-4f8b-8c72-6cfcae0a0cd4'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col3 = await client.get_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"], datasets[\"id\"], \"new_column_3\"\n",
    ")\n",
    "col3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'new_column_3',\n",
       " 'name': 'New Column 3 Updated',\n",
       " 'type': 'number',\n",
       " 'settings': {'id': 'new_column_3',\n",
       "  'name': 'New Column 3',\n",
       "  'type': 'text',\n",
       "  'max_length': 255,\n",
       "  'is_required': True},\n",
       " 'created_at': '2025-04-10T02:22:07.300895+00:00',\n",
       " 'updated_at': '2025-04-10T02:22:11.116882+00:00',\n",
       " 'datatable_id': 'ebc3dd3e-f88b-4f8b-8c72-6cfcae0a0cd4'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.update_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"],\n",
    "    datasets[\"id\"],\n",
    "    \"new_column_3\",\n",
    "    name=\"New Column 3 Updated\",\n",
    "    type=ColumnType.NUMBER.value,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.delete_dataset_column(\n",
    "    projects[\"items\"][0][\"id\"], datasets[\"id\"], \"new_column_3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows (for datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Dataset Rows ----\n",
    "@patch\n",
    "async def list_dataset_rows(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List rows in a dataset.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, row_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific row in a dataset.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new row in a dataset.\"\"\"\n",
    "    row_data = {\"id\": id, \"data\": data}\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows\", row_data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, row_id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing row in a dataset.\"\"\"\n",
    "    row_data = {\"data\": data}\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\",\n",
    "        row_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_dataset_row(\n",
    "    self: RagasApiClient, project_id: str, dataset_id: str, row_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a row from a dataset.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/datasets/{dataset_id}/rows/{row_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3374b891-8398-41bd-8f81-2867759df294'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '',\n",
       " 'data': {'id': '', 'new_column_3': 'name'},\n",
       " 'created_at': '2025-04-16T17:46:39.100525+00:00',\n",
       " 'updated_at': '2025-04-16T17:46:39.100525+00:00',\n",
       " 'datatable_id': '3374b891-8398-41bd-8f81-2867759df294'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_dataset_row(\n",
    "    project_id=projects[\"items\"][0][\"id\"],\n",
    "    dataset_id=datasets[\"id\"],\n",
    "    id=\"\",\n",
    "    data={\"new_column_3\": \"name\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Dataset Visualized - Created From UI\n",
    "Lets Create a new dataset and add columns and rows via the endpoint to see how it behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.app.ragas.io/dashboard/projects/e1b3f1e4-d344-48f4-a178-84e7e32e6ab6/datasets/dbccf6aa-b923-47ed-8e97-bd46f2f2cee8'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a dataset\n",
    "dataset = await client.create_dataset(\n",
    "    project_id=TEST_PROJECT_ID,\n",
    "    name=\"Dataset Visualized from UI\",\n",
    "    description=\"This is a dataset created from the UI\",\n",
    ")\n",
    "\n",
    "# show url\n",
    "WEB_ENDPOINT = \"https://dev.app.ragas.io\"\n",
    "url = f\"{WEB_ENDPOINT}/dashboard/projects/{TEST_PROJECT_ID}/datasets/{dataset['id']}\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns\n",
    "columns = await client.list_dataset_columns(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "# list rows\n",
    "rows = await client.list_dataset_rows(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 0,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [],\n",
       " 'pagination': {'offset': 0,\n",
       "  'limit': 50,\n",
       "  'total': 0,\n",
       "  'order_by': 'created_at',\n",
       "  'sort_dir': 'asc'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset from data\n",
    "\n",
    "we want to be able to use the API with python data like this `t.List[t.Dict]`.\n",
    "```py\n",
    "# how we want the data to look\n",
    "data = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"query\": \"What is the capital of Germany?\",\n",
    "        \"persona\": \"Jane\",\n",
    "        \"ground_truth\": \"Berlin\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"query\": \"What is the capital of Italy?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Rome\",\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number', 'text', 'longText', 'select', 'date', 'multiSelect', 'checkbox', 'custom']\n"
     ]
    }
   ],
   "source": [
    "# print out column types\n",
    "print([col.value for col in ColumnType])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should be able to handle simple python dicts\n",
    "data = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"persona\": \"John\",\n",
    "        \"ground_truth\": \"Paris\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"query\": \"What is the capital of Germany?\",\n",
    "        \"persona\": \"Jane\",\n",
    "        \"ground_truth\": \"Berlin\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be 2 ways to pass in data\n",
    "\n",
    "1. Data can come as either as simple dicts\n",
    "\n",
    "```py\n",
    "data = [\n",
    "    {\"column_1\": \"value\", \"column_2\": \"value\"}\n",
    "]\n",
    "```\n",
    "\n",
    "2. or if you want to give more settings\n",
    "\n",
    "```py\n",
    "data = [\n",
    "    {\n",
    "        \"column_1\": {\"data\": \"value\", \"type\": ColumnType.text},\n",
    "        \"column_2\": {\"data\": \"value\", \"type\": ColumnType.number},\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "3. after that you will have to pass a list `Column` and `Row` to add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data_columns = [\n",
    "    {\"name\": \"id\", \"type\": ColumnType.NUMBER.value},\n",
    "    {\"name\": \"query\", \"type\": ColumnType.TEXT.value},\n",
    "    {\"name\": \"persona\", \"type\": ColumnType.TEXT.value},\n",
    "    {\"name\": \"ground_truth\", \"type\": ColumnType.TEXT.value},\n",
    "]\n",
    "\n",
    "test_data_rows = [{\n",
    "    \"id\": \"1\",\n",
    "    \"query\": \"What is the capital of France?\",\n",
    "    \"persona\": \"John\",\n",
    "    \"ground_truth\": \"Paris\",\n",
    "}, {\n",
    "    \"id\": \"2\",\n",
    "    \"query\": \"What is the capital of Germany?\",\n",
    "    \"persona\": \"Jane\",\n",
    "    \"ground_truth\": \"Berlin\",\n",
    "}, {\n",
    "    \"id\": \"3\",\n",
    "    \"query\": \"What is the capital of Italy?\",\n",
    "    \"persona\": \"John\",\n",
    "    \"ground_truth\": \"Rome\",\n",
    "}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uuid\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_nano_id(size=12):\n",
    "    # Define characters to use (alphanumeric)\n",
    "    alphabet = string.ascii_letters + string.digits\n",
    "    \n",
    "    # Generate UUID and convert to int\n",
    "    uuid_int = uuid.uuid4().int\n",
    "    \n",
    "    # Convert to base62\n",
    "    result = \"\"\n",
    "    while uuid_int:\n",
    "        uuid_int, remainder = divmod(uuid_int, len(alphabet))\n",
    "        result = alphabet[remainder] + result\n",
    "    \n",
    "    # Pad if necessary and return desired length\n",
    "    return result[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anvz5k9geU7T'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "nano_id = create_nano_id()  # e.g., \"8dK9cNw3mP5x\"\n",
    "nano_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uuid\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_nano_id(size=12):\n",
    "    # Define characters to use (alphanumeric)\n",
    "    alphabet = string.ascii_letters + string.digits\n",
    "    \n",
    "    # Generate UUID and convert to int\n",
    "    uuid_int = uuid.uuid4().int\n",
    "    \n",
    "    # Convert to base62\n",
    "    result = \"\"\n",
    "    while uuid_int:\n",
    "        uuid_int, remainder = divmod(uuid_int, len(alphabet))\n",
    "        result = alphabet[remainder] + result\n",
    "    \n",
    "    # Pad if necessary and return desired length\n",
    "    return result[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anvz5k9geU7T'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "nano_id = create_nano_id()  # e.g., \"8dK9cNw3mP5x\"\n",
    "nano_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Default settings for columns\n",
    "DEFAULT_SETTINGS = {\n",
    "    \"is_required\": False,\n",
    "    \"max_length\": 1000\n",
    "}\n",
    "\n",
    "# Model definitions\n",
    "class Column(BaseModel):\n",
    "    id: str = Field(default_factory=create_nano_id)\n",
    "    name: str = Field(...)\n",
    "    type: str = Field(...)\n",
    "    settings: t.Dict = Field(default_factory=lambda: DEFAULT_SETTINGS.copy())\n",
    "    col_order: t.Optional[int] = Field(default=None)\n",
    "\n",
    "class RowCell(BaseModel):\n",
    "    data: t.Any = Field(...)\n",
    "    column_id: str = Field(...)\n",
    "\n",
    "class Row(BaseModel):\n",
    "    id: str = Field(default_factory=create_nano_id)\n",
    "    data: t.List[RowCell] = Field(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Resource With Data Helper Methods ----\n",
    "@patch\n",
    "async def _create_with_data(\n",
    "    self: RagasApiClient,\n",
    "    resource_type: str,\n",
    "    project_id: str,\n",
    "    name: str, \n",
    "    description: str,\n",
    "    columns: t.List[Column],\n",
    "    rows: t.List[Row],\n",
    "    batch_size: int = 50\n",
    ") -> t.Dict:\n",
    "    \"\"\"Generic method to create a resource with columns and rows.\n",
    "    \n",
    "    Args:\n",
    "        resource_type: Type of resource (\"dataset\" or \"experiment\")\n",
    "        project_id: Project ID\n",
    "        name: Resource name\n",
    "        description: Resource description\n",
    "        columns: List of column definitions\n",
    "        rows: List of row data\n",
    "        batch_size: Number of operations to perform concurrently\n",
    "        \n",
    "    Returns:\n",
    "        The created resource\n",
    "    \"\"\"\n",
    "    # Select appropriate methods based on resource type\n",
    "    if resource_type == \"dataset\":\n",
    "        create_fn = self.create_dataset\n",
    "        create_col_fn = self.create_dataset_column\n",
    "        create_row_fn = self.create_dataset_row\n",
    "        delete_fn = self.delete_dataset\n",
    "        id_key = \"dataset_id\"\n",
    "    elif resource_type == \"experiment\":\n",
    "        create_fn = self.create_experiment\n",
    "        create_col_fn = self.create_experiment_column\n",
    "        create_row_fn = self.create_experiment_row\n",
    "        delete_fn = self.delete_experiment\n",
    "        id_key = \"experiment_id\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported resource type: {resource_type}\")\n",
    "        \n",
    "    try:\n",
    "        # Create the resource\n",
    "        resource = await create_fn(project_id, name, description)\n",
    "        \n",
    "        # Process columns in batches\n",
    "        for i in range(0, len(columns), batch_size):\n",
    "            batch = columns[i:i+batch_size]\n",
    "            col_tasks = []\n",
    "            \n",
    "            for col in batch:\n",
    "                params = {\n",
    "                    \"project_id\": project_id,\n",
    "                    id_key: resource[\"id\"], # dataset_id here\n",
    "                    \"id\": col.id,\n",
    "                    \"name\": col.name,\n",
    "                    \"type\": col.type,\n",
    "                    \"settings\": col.settings\n",
    "                }\n",
    "                if col.col_order is not None:\n",
    "                    params[\"col_order\"] = col.col_order\n",
    "                \n",
    "                col_tasks.append(create_col_fn(**params))\n",
    "            \n",
    "            await asyncio.gather(*col_tasks)\n",
    "            \n",
    "        # Process rows in batches\n",
    "        for i in range(0, len(rows), batch_size):\n",
    "            batch = rows[i:i+batch_size]\n",
    "            row_tasks = []\n",
    "            \n",
    "            for row in batch:\n",
    "                row_data = {cell.column_id: cell.data for cell in row.data}\n",
    "                row_tasks.append(\n",
    "                    create_row_fn(\n",
    "                        project_id=project_id,\n",
    "                        **{id_key: resource[\"id\"]},\n",
    "                        id=row.id,\n",
    "                        data=row_data\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            await asyncio.gather(*row_tasks)\n",
    "            \n",
    "        return resource\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Clean up on error\n",
    "        if 'resource' in locals():\n",
    "            try:\n",
    "                await delete_fn(project_id, resource[\"id\"])\n",
    "            except:\n",
    "                pass  # Ignore cleanup errors\n",
    "        raise e\n",
    "\n",
    "@patch\n",
    "async def create_dataset_with_data(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    name: str,\n",
    "    description: str,\n",
    "    columns: t.List[Column],\n",
    "    rows: t.List[Row],\n",
    "    batch_size: int = 50\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a dataset with columns and rows.\n",
    "    \n",
    "    This method creates a dataset and populates it with columns and rows in an\n",
    "    optimized way using concurrent requests.\n",
    "    \n",
    "    Args:\n",
    "        project_id: Project ID\n",
    "        name: Dataset name\n",
    "        description: Dataset description\n",
    "        columns: List of column definitions\n",
    "        rows: List of row data\n",
    "        batch_size: Number of operations to perform concurrently\n",
    "        \n",
    "    Returns:\n",
    "        The created dataset\n",
    "    \"\"\"\n",
    "    return await self._create_with_data(\n",
    "        \"dataset\", project_id, name, description, columns, rows, batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with ID: 5e7912f4-6a65-4d0c-bf79-0fab9ddda40c\n",
      "Created 4 columns\n",
      "Created 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Create Column objects\n",
    "column_objects = []\n",
    "for col in test_data_columns:\n",
    "    column_objects.append(Column(\n",
    "        name=col[\"name\"],\n",
    "        type=col[\"type\"]\n",
    "        # id and settings will be auto-generated\n",
    "    ))\n",
    "\n",
    "# Create a mapping of column names to their IDs for creating rows\n",
    "column_map = {col.name: col.id for col in column_objects}\n",
    "\n",
    "# Create Row objects\n",
    "row_objects = []\n",
    "for row in test_data_rows:\n",
    "    cells = []\n",
    "    for key, value in row.items():\n",
    "        if key in column_map:  # Skip any extra fields not in columns\n",
    "            cells.append(RowCell(\n",
    "                data=value,\n",
    "                column_id=column_map[key]\n",
    "            ))\n",
    "    row_objects.append(Row(data=cells))\n",
    "\n",
    "# Now we can create the dataset\n",
    "dataset = await client.create_dataset_with_data(\n",
    "    project_id=TEST_PROJECT_ID,\n",
    "    name=\"Capitals Dataset\",\n",
    "    description=\"A dataset about capital cities\",\n",
    "    columns=column_objects,\n",
    "    rows=row_objects\n",
    ")\n",
    "\n",
    "print(f\"Created dataset with ID: {dataset['id']}\")\n",
    "\n",
    "# Verify the data\n",
    "columns = await client.list_dataset_columns(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "print(f\"Created {len(columns['items'])} columns\")\n",
    "\n",
    "rows = await client.list_dataset_rows(TEST_PROJECT_ID, dataset[\"id\"])\n",
    "print(f\"Created {len(rows['items'])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dev.app.ragas.io/dashboard/projects/e1b3f1e4-d344-48f4-a178-84e7e32e6ab6/datasets/5e7912f4-6a65-4d0c-bf79-0fab9ddda40c'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dataset url\n",
    "url = f\"{WEB_ENDPOINT}/dashboard/projects/{TEST_PROJECT_ID}/datasets/{dataset['id']}\"\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "await client.delete_dataset(TEST_PROJECT_ID, dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same but for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Experiment Columns ----\n",
    "@patch\n",
    "async def list_experiment_columns(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List columns in an experiment.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_experiment_column(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, column_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific column in an experiment.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_experiment_column(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    id: str,\n",
    "    name: str,\n",
    "    type: str,\n",
    "    col_order: t.Optional[int] = None,\n",
    "    settings: t.Optional[t.Dict] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new column in an experiment.\"\"\"\n",
    "    data = {\"id\": id, \"name\": name, \"type\": type}\n",
    "    if col_order is not None:\n",
    "        data[\"col_order\"] = col_order\n",
    "    if settings:\n",
    "        data[\"settings\"] = settings\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns\", data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_experiment_column(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, column_id: str, **column_data\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing column in an experiment.\"\"\"\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\",\n",
    "        column_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_experiment_column(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, column_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a column from an experiment.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/columns/{column_id}\"\n",
    "    )\n",
    "\n",
    "#---- Experiment Rows ----\n",
    "@patch\n",
    "async def list_experiment_rows(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    experiment_id: str,\n",
    "    limit: int = 50,\n",
    "    offset: int = 0,\n",
    "    order_by: t.Optional[str] = None,\n",
    "    sort_dir: t.Optional[str] = None,\n",
    ") -> t.Dict:\n",
    "    \"\"\"List rows in an experiment.\"\"\"\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if order_by:\n",
    "        params[\"order_by\"] = order_by\n",
    "    if sort_dir:\n",
    "        params[\"sort_dir\"] = sort_dir\n",
    "    return await self._list_resources(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows\", **params\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def get_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, row_id: str\n",
    ") -> t.Dict:\n",
    "    \"\"\"Get a specific row in an experiment.\"\"\"\n",
    "    return await self._get_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\"\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def create_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create a new row in an experiment.\"\"\"\n",
    "    row_data = {\"id\": id, \"data\": data}\n",
    "    return await self._create_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows\", row_data\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def update_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, row_id: str, data: t.Dict\n",
    ") -> t.Dict:\n",
    "    \"\"\"Update an existing row in an experiment.\"\"\"\n",
    "    row_data = {\"data\": data}\n",
    "    return await self._update_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\",\n",
    "        row_data,\n",
    "    )\n",
    "\n",
    "@patch\n",
    "async def delete_experiment_row(\n",
    "    self: RagasApiClient, project_id: str, experiment_id: str, row_id: str\n",
    ") -> None:\n",
    "    \"\"\"Delete a row from an experiment.\"\"\"\n",
    "    await self._delete_resource(\n",
    "        f\"projects/{project_id}/experiments/{experiment_id}/rows/{row_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7c695b58-7fc3-464c-a18b-a96e35f9684d',\n",
       " 'name': 'New Experiment',\n",
       " 'description': 'This is a new experiment',\n",
       " 'updated_at': '2025-04-09T17:03:44.340782+00:00',\n",
       " 'created_at': '2025-04-09T17:03:44.340782+00:00',\n",
       " 'version_counter': 0,\n",
       " 'project_id': 'e1b3f1e4-d344-48f4-a178-84e7e32e6ab6'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.create_experiment(TEST_PROJECT_ID, \"New Experiment\", \"This is a new experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78fd6c58-7edf-4239-93d1-4f49185d8e49'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = await client.list_experiments(TEST_PROJECT_ID)\n",
    "EXPERIMENT_ID = experiments[\"items\"][0][\"id\"]\n",
    "EXPERIMENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def create_experiment_with_data(\n",
    "    self: RagasApiClient,\n",
    "    project_id: str,\n",
    "    name: str,\n",
    "    description: str,\n",
    "    columns: t.List[Column],\n",
    "    rows: t.List[Row],\n",
    "    batch_size: int = 50\n",
    ") -> t.Dict:\n",
    "    \"\"\"Create an experiment with columns and rows.\n",
    "    \n",
    "    This method creates an experiment and populates it with columns and rows in an\n",
    "    optimized way using concurrent requests.\n",
    "    \n",
    "    Args:\n",
    "        project_id: Project ID\n",
    "        name: Experiment name\n",
    "        description: Experiment description\n",
    "        columns: List of column definitions\n",
    "        rows: List of row data\n",
    "        batch_size: Number of operations to perform concurrently\n",
    "        \n",
    "    Returns:\n",
    "        The created experiment\n",
    "    \"\"\"\n",
    "    return await self._create_with_data(\n",
    "        \"experiment\", project_id, name, description, columns, rows, batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#---- Utility Methods ----\n",
    "@patch\n",
    "def create_column(\n",
    "    self: RagasApiClient, \n",
    "    name: str, \n",
    "    type: str, \n",
    "    settings: t.Optional[t.Dict] = None, \n",
    "    col_order: t.Optional[int] = None,\n",
    "    id: t.Optional[str] = None\n",
    ") -> Column:\n",
    "    \"\"\"Create a Column object.\n",
    "    \n",
    "    Args:\n",
    "        name: Column name\n",
    "        type: Column type (use ColumnType enum)\n",
    "        settings: Column settings\n",
    "        col_order: Column order\n",
    "        id: Custom ID (generates one if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Column object\n",
    "    \"\"\"\n",
    "    params = {\"name\": name, \"type\": type}\n",
    "    if settings:\n",
    "        params[\"settings\"] = settings\n",
    "    if col_order is not None:\n",
    "        params[\"col_order\"] = col_order\n",
    "    if id:\n",
    "        params[\"id\"] = id\n",
    "        \n",
    "    return Column(**params)\n",
    "    \n",
    "@patch\n",
    "def create_row(\n",
    "    self: RagasApiClient, \n",
    "    data: t.Dict[str, t.Any], \n",
    "    column_map: t.Dict[str, str],\n",
    "    id: t.Optional[str] = None\n",
    ") -> Row:\n",
    "    \"\"\"Create a Row object from a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary mapping column names to values\n",
    "        column_map: Dictionary mapping column names to column IDs\n",
    "        id: Custom ID (generates one if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        Row object\n",
    "    \"\"\"\n",
    "    cells = []\n",
    "    for col_name, value in data.items():\n",
    "        if col_name in column_map:\n",
    "            cells.append(RowCell(\n",
    "                data=value,\n",
    "                column_id=column_map[col_name]\n",
    "            ))\n",
    "            \n",
    "    params = {\"data\": cells}\n",
    "    if id:\n",
    "        params[\"id\"] = id\n",
    "        \n",
    "    return Row(**params)\n",
    "    \n",
    "@patch\n",
    "def create_column_map(self: RagasApiClient, columns: t.List[Column]) -> t.Dict[str, str]:\n",
    "    \"\"\"Create a mapping of column names to IDs.\n",
    "    \n",
    "    Args:\n",
    "        columns: List of column objects\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping column names to IDs\n",
    "    \"\"\"\n",
    "    return {col.name: col.id for col in columns}\n",
    "    \n",
    "@patch\n",
    "async def convert_raw_data(\n",
    "    self: RagasApiClient,\n",
    "    column_defs: t.List[t.Dict],\n",
    "    row_data: t.List[t.Dict]\n",
    ") -> t.Tuple[t.List[Column], t.List[Row]]:\n",
    "    \"\"\"Convert raw data to column and row objects.\n",
    "    \n",
    "    Args:\n",
    "        column_defs: List of column definitions (dicts with name, type)\n",
    "        row_data: List of dictionaries with row data\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (columns, rows)\n",
    "    \"\"\"\n",
    "    # Create columns\n",
    "    columns = []\n",
    "    for col in column_defs:\n",
    "        columns.append(self.create_column(**col))\n",
    "        \n",
    "    # Create column map\n",
    "    column_map = self.create_column_map(columns)\n",
    "    \n",
    "    # Create rows\n",
    "    rows = []\n",
    "    for data in row_data:\n",
    "        rows.append(self.create_row(data, column_map))\n",
    "        \n",
    "    return columns, rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
