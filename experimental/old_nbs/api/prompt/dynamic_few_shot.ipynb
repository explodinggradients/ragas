{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prompt.dynamic_few_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import typing as t\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from ragas_experimental.prompt.base import Prompt\n",
    "from ragas_experimental.embedding import BaseEmbedding\n",
    "\n",
    "class ExampleStore(ABC):\n",
    "    @abstractmethod\n",
    "    def get_examples(\n",
    "        self, data: t.Dict, top_k: int = 5\n",
    "    ) -> t.List[t.Tuple[t.Dict, t.Dict]]:\n",
    "        \"\"\"Get top_k most similar examples to data.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_example(self, inputs: t.Dict, output: t.Dict) -> None:\n",
    "        \"\"\"Add an example to the store.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class InMemoryExampleStore(ExampleStore):\n",
    "    def __init__(self, embedding_model=None):\n",
    "        \"\"\"\n",
    "        Initialize an in-memory example store with optional embedding model.\n",
    "        \n",
    "        Args:\n",
    "            embedding_model: Model used to generate embeddings (OpenAI or similar)\n",
    "        \"\"\"\n",
    "        self.embedding_model = embedding_model\n",
    "        self._examples: t.List[t.Tuple[t.Dict, t.Dict]] = []\n",
    "        self._embeddings_list: t.List[t.List[float]] = []\n",
    "    \n",
    "    def _get_embedding(self, data: t.Dict) -> t.List[float]:\n",
    "        \"\"\"Convert input dict to an embedding vector.\"\"\"\n",
    "        if self.embedding_model is None:\n",
    "            return []\n",
    "        \n",
    "        # Serialize the dictionary to text\n",
    "        text = \"\\n\".join([f\"{k}: {v}\" for k, v in data.items()])\n",
    "        return self.embedding_model.embed_text(text)\n",
    "    \n",
    "    def add_example(self, inputs: t.Dict, output: t.Dict) -> None:\n",
    "        \"\"\"Add an example to the store with its embedding.\"\"\"\n",
    "        if not isinstance(inputs, dict):\n",
    "            raise TypeError(f\"Expected inputs to be dict, got {type(inputs).__name__}\")\n",
    "        if not isinstance(output, dict):\n",
    "            raise TypeError(f\"Expected output to be dict, got {type(output).__name__}\")\n",
    "            \n",
    "        self._examples.append((inputs, output))\n",
    "        \n",
    "        if self.embedding_model:\n",
    "            embedding = self._get_embedding(inputs)\n",
    "            self._embeddings_list.append(embedding)\n",
    "    \n",
    "    def get_examples(\n",
    "        self, data: t.Dict, top_k: int = 5, threshold: float = 0.7\n",
    "    ) -> t.List[t.Tuple[t.Dict, t.Dict]]:\n",
    "        \"\"\"Get examples most similar to the input data.\"\"\"\n",
    "        if not self._examples:\n",
    "            return []\n",
    "            \n",
    "        if not self.embedding_model or not self._embeddings_list:\n",
    "            # If no embedding model, return the most recent examples\n",
    "            return self._examples[-top_k:]\n",
    "        \n",
    "        # Get embedding for the query\n",
    "        query_embedding = self._get_embedding(data)\n",
    "        \n",
    "        # Find most similar examples\n",
    "        indices = self._get_nearest_examples(\n",
    "            query_embedding, self._embeddings_list, top_k, threshold\n",
    "        )\n",
    "        \n",
    "        # Return the examples at those indices\n",
    "        return [self._examples[i] for i in indices]\n",
    "    \n",
    "    def _get_nearest_examples(\n",
    "        self,\n",
    "        query_embedding: t.List[float],\n",
    "        embeddings: t.List[t.List[float]],\n",
    "        top_k: int = 3,\n",
    "        threshold: float = 0.7,\n",
    "    ) -> t.List[int]:\n",
    "        \"\"\"Find indices of the nearest examples based on cosine similarity.\"\"\"\n",
    "        # Convert to numpy arrays for efficient computation\n",
    "        query = np.array(query_embedding)\n",
    "        embed_matrix = np.array(embeddings)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarities = np.dot(embed_matrix, query) / (\n",
    "            np.linalg.norm(embed_matrix, axis=1) * np.linalg.norm(query) + 1e-8\n",
    "        )\n",
    "        \n",
    "        # Get indices of similarities above threshold\n",
    "        valid_indices = np.where(similarities >= threshold)[0]\n",
    "        \n",
    "        # Sort by similarity and get top-k\n",
    "        if len(valid_indices) > 0:\n",
    "            top_indices = valid_indices[np.argsort(similarities[valid_indices])[-top_k:]]\n",
    "            # Convert numpy indices to Python ints\n",
    "            return [int(idx) for idx in top_indices]\n",
    "        \n",
    "        # If no examples meet threshold, return most recent examples\n",
    "        return list(range(max(0, len(embeddings) - top_k), len(embeddings)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._examples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DynamicFewShotPrompt(Prompt):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        prompt: Prompt,\n",
    "        example_store: InMemoryExampleStore,\n",
    "        num_examples: int = 3\n",
    "    ):\n",
    "        \n",
    "        self.example_store = example_store\n",
    "        super().__init__(prompt.instruction, prompt.examples)\n",
    "        self.num_examples = num_examples\n",
    "        \n",
    "        for example in prompt.examples:\n",
    "            self.example_store.add_example(*example)\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        \"\"\"Format the prompt with dynamically retrieved examples.\"\"\"\n",
    "        prompt_parts = []\n",
    "        \n",
    "        # Add instruction with variables filled in\n",
    "        prompt_parts.append(self.instruction.format(**kwargs))\n",
    "        \n",
    "        # Get dynamic examples if we have a store and inputs\n",
    "        dynamic_examples = []\n",
    "        if self.example_store and kwargs:\n",
    "            dynamic_examples = self.example_store.get_examples(kwargs, self.num_examples)\n",
    "        \n",
    "        # Add examples in a simple format\n",
    "        if dynamic_examples:\n",
    "            prompt_parts.append(\"Examples:\")\n",
    "            for i, (inputs, output) in enumerate(dynamic_examples, 1):\n",
    "                example_input = \"\\n\".join([f\"{k}: {v}\" for k, v in inputs.items()])\n",
    "                example_output = \"\\n\".join([f\"{k}: {v}\" for k, v in output.items()])\n",
    "                \n",
    "                prompt_parts.append(f\"Example {i}:\\nInput:\\n{example_input}\\nOutput:\\n{example_output}\")\n",
    "        \n",
    " \n",
    "        \n",
    "        # Combine all parts\n",
    "        return \"\\n\\n\".join(prompt_parts)\n",
    "    \n",
    "    def add_example(self, inputs: t.Dict, output: t.Dict) -> None:\n",
    "        \"\"\"\n",
    "        Add an example to both the prompt and the example store.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        inputs : Dict\n",
    "            Dictionary of input values\n",
    "        output : Dict\n",
    "            Dictionary of output values\n",
    "            \n",
    "        Raises:\n",
    "        -------\n",
    "        TypeError\n",
    "            If inputs or output is not a dictionary\n",
    "        \"\"\"\n",
    "        if (inputs, output) not in self.examples:\n",
    "            self.examples.append((inputs, output))\n",
    "            \n",
    "        # Add to example store\n",
    "        if isinstance(self.example_store, ExampleStore) and (inputs, output) not in self.example_store._examples:\n",
    "            self.example_store.add_example(inputs, output)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_prompt(\n",
    "        cls,\n",
    "        prompt: Prompt,\n",
    "        embedding_model: BaseEmbedding,\n",
    "        num_examples: int = 3\n",
    "    ) -> \"DynamicFewShotPrompt\":\n",
    "        \"\"\"Create a DynamicFewShotPrompt from a Prompt object.\"\"\"\n",
    "        example_store = InMemoryExampleStore(embedding_model=embedding_model)\n",
    "        \n",
    "        few_shot_prompt = cls(\n",
    "            prompt=prompt,\n",
    "            example_store=example_store,\n",
    "            num_examples=num_examples\n",
    "        )\n",
    "        \n",
    "        return few_shot_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate if given answer Regularly updating your software reduces the risk of vulnerabilities. is same as expected answer Keeping software up to date helps patch known security flaws and prevents exploits.\n",
      "\n",
      "Examples:\n",
      "\n",
      "Example 1:\n",
      "Input:\n",
      "response: Using two-factor authentication greatly enhances account security.\n",
      "expected_answer: Two-factor authentication adds a layer of protection by requiring a second form of identity verification.\n",
      "Output:\n",
      "score: fail\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from ragas_experimental.embedding import ragas_embedding\n",
    "from ragas_experimental.prompt import Prompt\n",
    "from openai import OpenAI\n",
    "\n",
    "embedding = ragas_embedding(provider=\"openai\", client=OpenAI(),model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create a basic prompt\n",
    "prompt = Prompt(\n",
    "    instruction=\"Evaluate if given answer {response} is same as expected answer {expected_answer}\"\n",
    ")\n",
    "\n",
    "# Add examples with dict inputs and dict outputs\n",
    "prompt.add_example(\n",
    "    {\n",
    "        \"response\": \"You can get a full refund if you miss your flight.\",\n",
    "        \"expected_answer\": \"Refunds depend on ticket type; only refundable tickets qualify for full refunds.\"\n",
    "    },\n",
    "    {\"score\": \"fail\"}\n",
    ")\n",
    "\n",
    "prompt = DynamicFewShotPrompt.from_prompt(\n",
    "    prompt,\n",
    "    embedding_model=embedding,\n",
    "    num_examples=1\n",
    ")\n",
    "\n",
    "prompt.add_example(\n",
    "    {\n",
    "        \"response\": \"Bananas are high in potassium and great for quick energy.\",\n",
    "        \"expected_answer\": \"Bananas provide potassium and are a good source of fast-digesting carbohydrates.\"\n",
    "    },\n",
    "    {\"score\": \"pass\"}\n",
    ")\n",
    "\n",
    "prompt.add_example(\n",
    "    {\n",
    "        \"response\": \"Using two-factor authentication greatly enhances account security.\",\n",
    "        \"expected_answer\": \"Two-factor authentication adds a layer of protection by requiring a second form of identity verification.\"\n",
    "    },\n",
    "    {\"score\": \"fail\"}\n",
    ")\n",
    "\n",
    "\n",
    "prompt.example_store.get_examples(\n",
    "{\n",
    "        \"response\": \"Regularly updating your software reduces the risk of vulnerabilities.\",\n",
    "        \"expected_answer\": \"Keeping software up to date helps patch known security flaws and prevents exploits.\"\n",
    "    })\n",
    "\n",
    "print(prompt.format(**{\n",
    "        \"response\": \"Regularly updating your software reduces the risk of vulnerabilities.\",\n",
    "        \"expected_answer\": \"Keeping software up to date helps patch known security flaws and prevents exploits.\"\n",
    "    }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
