from ragas.metrics._answer_correctness import AnswerCorrectness, answer_correctness
from ragas.metrics._answer_relevance import (
    AnswerRelevancy,
    ResponseRelevancy,
    answer_relevancy,
)
from ragas.metrics._answer_similarity import (
    AnswerSimilarity,
    SemanticSimilarity,
    answer_similarity,
)
from ragas.metrics._aspect_critic import AspectCritic
from ragas.metrics._bleu_score import BleuScore
from ragas.metrics._context_entities_recall import (
    ContextEntityRecall,
    context_entity_recall,
)
from ragas.metrics._context_precision import (
    ContextPrecision,
    ContextUtilization,
    LLMContextPrecisionWithoutReference,
    LLMContextPrecisionWithReference,
    NonLLMContextPrecisionWithReference,
    context_precision,
)
from ragas.metrics._context_recall import (
    ContextRecall,
    LLMContextRecall,
    NonLLMContextRecall,
    context_recall,
)
from ragas.metrics._datacompy_score import DataCompyScore
from ragas.metrics._domain_specific_rubrics import RubricsScore
from ragas.metrics._factual_correctness import FactualCorrectness
from ragas.metrics._faithfulness import Faithfulness, FaithfulnesswithHHEM, faithfulness
from ragas.metrics._goal_accuracy import (
    AgentGoalAccuracyWithoutReference,
    AgentGoalAccuracyWithReference,
)
from ragas.metrics._instance_specific_rubrics import InstanceRubrics
from ragas.metrics._multi_modal_faithfulness import (
    MultiModalFaithfulness,
    multimodal_faithness,
)
from ragas.metrics._multi_modal_relevance import (
    MultiModalRelevance,
    multimodal_relevance,
)
from ragas.metrics._noise_sensitivity import NoiseSensitivity
from ragas.metrics._nv_metrics import (
    AnswerAccuracy,
    ContextRelevance,
    ResponseGroundedness,
)
from ragas.metrics._rouge_score import RougeScore
from ragas.metrics._simple_criteria import SimpleCriteriaScore
from ragas.metrics._sql_semantic_equivalence import LLMSQLEquivalence
from ragas.metrics._string import (
    DistanceMeasure,
    ExactMatch,
    NonLLMStringSimilarity,
    StringPresence,
)
from ragas.metrics._summarization import SummarizationScore, summarization_score
from ragas.metrics._tool_call_accuracy import ToolCallAccuracy
from ragas.metrics._topic_adherence import TopicAdherenceScore
from ragas.metrics.base import (
    Metric,
    MetricOutputType,
    MetricType,
    MetricWithEmbeddings,
    MetricWithLLM,
    MultiTurnMetric,
    SingleTurnMetric,
)
from ragas.metrics.discrete import DiscreteMetric, discrete_metric
from ragas.metrics.llm_based import BaseLLMMetric, LLMMetric
from ragas.metrics.numeric import NumericMetric, numeric_metric
from ragas.metrics.ranking import RankingMetric, ranking_metric
from ragas.metrics.result import MetricResult

__all__ = [
    # basic metrics primitives
    "Metric",
    "MetricType",
    "MetricWithEmbeddings",
    "MetricWithLLM",
    "SingleTurnMetric",
    "MultiTurnMetric",
    "MetricOutputType",
    # LLM-based metrics (moved from experimental)
    "BaseLLMMetric",
    "LLMMetric",
    "MetricResult",
    "DiscreteMetric",
    "NumericMetric",
    "RankingMetric",
    "discrete_metric",
    "numeric_metric",
    "ranking_metric",
    # specific metrics
    "AnswerAccuracy",
    "ContextRelevance",
    "ResponseGroundedness",
    "AnswerCorrectness",
    "answer_correctness",
    "Faithfulness",
    "faithfulness",
    "FaithfulnesswithHHEM",
    "AnswerSimilarity",
    "answer_similarity",
    "ContextPrecision",
    "context_precision",
    "ContextUtilization",
    "SimpleCriteriaScore",
    "ContextRecall",
    "context_recall",
    "AspectCritic",
    "AnswerRelevancy",
    "answer_relevancy",
    "ContextEntityRecall",
    "context_entity_recall",
    "SummarizationScore",
    "summarization_score",
    "NoiseSensitivity",
    "RubricsScore",
    "LLMContextPrecisionWithReference",
    "LLMContextPrecisionWithoutReference",
    "NonLLMContextPrecisionWithReference",
    "LLMContextPrecisionWithoutReference",
    "LLMContextRecall",
    "NonLLMContextRecall",
    "FactualCorrectness",
    "InstanceRubrics",
    "NonLLMStringSimilarity",
    "ExactMatch",
    "StringPresence",
    "BleuScore",
    "RougeScore",
    "DataCompyScore",
    "LLMSQLEquivalence",
    "AgentGoalAccuracyWithoutReference",
    "AgentGoalAccuracyWithReference",
    "ToolCallAccuracy",
    "ResponseRelevancy",
    "SemanticSimilarity",
    "DistanceMeasure",
    "TopicAdherenceScore",
    "LLMSQLEquivalence",
    "MultiModalFaithfulness",
    "multimodal_faithness",
    "MultiModalRelevance",
    "multimodal_relevance",
]

# Backward compatibility aliases for experimental imports
# These maintain compatibility while experimental code is migrated
BaseMetric = BaseLLMMetric  # experimental BaseMetric -> BaseLLMMetric
