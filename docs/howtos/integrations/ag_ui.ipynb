{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcdd4d1",
   "metadata": {},
   "source": [
    "# AG-UI Integration\n",
    "Ragas can evaluate agents that stream events via the [AG-UI protocol](https://docs.ag-ui.com/). This notebook shows how to build evaluation datasets, configure metrics, and score AG-UI endpoints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0af3e1",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Install optional dependencies with `pip install \"ragas[ag-ui]\" langchain-openai python-dotenv nest_asyncio`\n",
    "- Start an AG-UI compatible agent locally (Google ADK, PydanticAI, CrewAI, etc.)\n",
    "- Create an `.env` file with your evaluator LLM credentials (e.g. `OPENAI_API_KEY`, `GOOGLE_API_KEY`, etc.)\n",
    "- If you run this notebook, call `nest_asyncio.apply()` (shown below) so you can `await` coroutines in-place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b16d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"ragas[ag-ui]\" langchain-openai python-dotenv nest_asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486082d",
   "metadata": {},
   "source": [
    "## Imports and environment setup\n",
    "Load environment variables and import the classes used throughout the walkthrough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c051059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "from IPython.display import display\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from ragas.dataset_schema import EvaluationDataset, SingleTurnSample, MultiTurnSample\n",
    "from ragas.integrations.ag_ui import (\n",
    "    evaluate_ag_ui_agent,\n",
    "    convert_to_ragas_messages,\n",
    "    convert_messages_snapshot,\n",
    ")\n",
    "from ragas.messages import HumanMessage, ToolCall\n",
    "from ragas.metrics import FactualCorrectness, ToolCallF1\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ag_ui.core import (\n",
    "    MessagesSnapshotEvent,\n",
    "    TextMessageChunkEvent,\n",
    "    UserMessage,\n",
    "    AssistantMessage,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "# Patch the existing notebook loop so we can await coroutines safely\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e69bc6c",
   "metadata": {},
   "source": [
    "## Build single-turn evaluation data\n",
    "Create `SingleTurnSample` entries when you only need to grade the final answer text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803cc334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'reference'], len=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientist_questions = EvaluationDataset(\n",
    "    samples=[\n",
    "        SingleTurnSample(\n",
    "            user_input=\"Who originated the theory of relativity?\",\n",
    "            reference=\"Albert Einstein originated the theory of relativity.\",\n",
    "        ),\n",
    "        SingleTurnSample(\n",
    "            user_input=\"Who discovered penicillin and when?\",\n",
    "            reference=\"Alexander Fleming discovered penicillin in 1928.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scientist_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1bbb7",
   "metadata": {},
   "source": [
    "## Build multi-turn conversations\n",
    "For tool-usage metrics, extend the dataset with `MultiTurnSample` and expected tool calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a55eb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'reference_tool_calls'], len=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_queries = EvaluationDataset(\n",
    "    samples=[\n",
    "        MultiTurnSample(\n",
    "            user_input=[HumanMessage(content=\"What's the weather in Paris?\")],\n",
    "            reference_tool_calls=[\n",
    "                ToolCall(name=\"weatherTool\", args={\"location\": \"Paris\"})\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "weather_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c3da95",
   "metadata": {},
   "source": [
    "## Configure metrics and the evaluator LLM\n",
    "Wrap your grading model with the appropriate adapter and instantiate the metrics you plan to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a59dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8k/tf3xr1rd1fl_dz35dfhfp_tc0000gn/T/ipykernel_93918/2135722072.py:1: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n"
     ]
    }
   ],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "qa_metrics = [FactualCorrectness(llm=evaluator_llm)]\n",
    "tool_metrics = [ToolCallF1()]  # rule-based, no LLM required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e65fe39",
   "metadata": {},
   "source": [
    "## Evaluate a live AG-UI endpoint\n",
    "Set the endpoint URL exposed by your agent. Toggle the flags when you are ready to run the evaluations.\n",
    "In Jupyter/IPython you can `await` the helpers directly once `nest_asyncio.apply()` has been called.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9808e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "AG_UI_ENDPOINT = \"http://localhost:8000/agentic_chat\"  # Update to match your agent\n",
    "\n",
    "RUN_FACTUAL_EVAL = False\n",
    "RUN_TOOL_EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79e80383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ae31282b934d0390f316f966690d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calling AG-UI Agent:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7449e7458a477da9b3bcfb5826b4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who originated the theory of relativity?</td>\n",
       "      <td>[]</td>\n",
       "      <td>The theory of relativity was originated by Alb...</td>\n",
       "      <td>Albert Einstein originated the theory of relat...</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who discovered penicillin and when?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Penicillin was discovered by Alexander Fleming...</td>\n",
       "      <td>Alexander Fleming discovered penicillin in 1928.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_input retrieved_contexts  \\\n",
       "0  Who originated the theory of relativity?                 []   \n",
       "1       Who discovered penicillin and when?                 []   \n",
       "\n",
       "                                            response  \\\n",
       "0  The theory of relativity was originated by Alb...   \n",
       "1  Penicillin was discovered by Alexander Fleming...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Albert Einstein originated the theory of relat...   \n",
       "1   Alexander Fleming discovered penicillin in 1928.   \n",
       "\n",
       "   factual_correctness(mode=f1)  \n",
       "0                          0.33  \n",
       "1                          1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async def evaluate_factual():\n",
    "    return await evaluate_ag_ui_agent(\n",
    "        endpoint_url=AG_UI_ENDPOINT,\n",
    "        dataset=scientist_questions,\n",
    "        metrics=qa_metrics,\n",
    "        evaluator_llm=evaluator_llm,\n",
    "        metadata=True,\n",
    "    )\n",
    "\n",
    "\n",
    "if RUN_FACTUAL_EVAL:\n",
    "    factual_result = await evaluate_factual()\n",
    "    factual_df = factual_result.to_pandas()\n",
    "    display(factual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b731189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351ca0c016cc46cd9c0321d43d283f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calling AG-UI Agent:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ea65a7bddf47b699d35813571e4d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_tool_calls</th>\n",
       "      <th>tool_call_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'What's the weather in Paris?', '...</td>\n",
       "      <td>[{'name': 'weatherTool', 'args': {'location': ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  [{'content': 'What's the weather in Paris?', '...   \n",
       "\n",
       "                                reference_tool_calls  tool_call_f1  \n",
       "0  [{'name': 'weatherTool', 'args': {'location': ...           0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async def evaluate_tool_usage():\n",
    "    return await evaluate_ag_ui_agent(\n",
    "        endpoint_url=AG_UI_ENDPOINT,\n",
    "        dataset=weather_queries,\n",
    "        metrics=tool_metrics,\n",
    "        evaluator_llm=evaluator_llm,\n",
    "    )\n",
    "\n",
    "\n",
    "if RUN_TOOL_EVAL:\n",
    "    tool_result = await evaluate_tool_usage()\n",
    "    tool_df = tool_result.to_pandas()\n",
    "    display(tool_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452627cf",
   "metadata": {},
   "source": [
    "## Convert recorded AG-UI events\n",
    "Use the conversion helpers when you already have an event log to grade offline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b691bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([AIMessage(content='Hello from AG-UI!', metadata={'timestamp': None, 'message_id': 'assistant-1'}, type='ai', tool_calls=None)],\n",
       " [HumanMessage(content='Hello?', metadata=None, type='human'),\n",
       "  AIMessage(content='Hi! How can I help you today?', metadata=None, type='ai', tool_calls=None)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = [\n",
    "    TextMessageChunkEvent(\n",
    "        message_id=\"assistant-1\",\n",
    "        role=\"assistant\",\n",
    "        delta=\"Hello from AG-UI!\",\n",
    "    )\n",
    "]\n",
    "\n",
    "messages_from_stream = convert_to_ragas_messages(events, metadata=True)\n",
    "\n",
    "snapshot = MessagesSnapshotEvent(\n",
    "    messages=[\n",
    "        UserMessage(id=\"msg-1\", content=\"Hello?\"),\n",
    "        AssistantMessage(id=\"msg-2\", content=\"Hi! How can I help you today?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages_from_snapshot = convert_messages_snapshot(snapshot)\n",
    "\n",
    "messages_from_stream, messages_from_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6235fd-ec1c-4e87-a53f-a2ebf89a29b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
